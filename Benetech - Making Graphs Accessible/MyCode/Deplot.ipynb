{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 教程\n",
    "### 中文教程:\n",
    "- https://transformers.run/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分词器\n",
    "\n",
    "由于神经网络模型不能直接处理文本，因此我们需要先将文本转换为数字，这个过程被称为编码 (Encoding)，其包含两个步骤：\n",
    "\n",
    "- 使用分词器 (tokenizer) 将文本按词、子词、字符切分为 tokens；\n",
    "- 将所有的 token 映射到对应的 token ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词表就是一个映射字典，负责将 token 映射到对应的 ID（从 0 开始）。神经网络模型就是通过这些 token ID 来区分每一个 token。\n",
    "\n",
    "当遇到不在词表中的词时，分词器会使用一个专门的 `UNK` token 来表示它是 unknown 的。显然，如果分词结果中包含很多 `UNK` 就意味着丢失了很多文本信息，因此一个好的分词策略，应该尽可能不出现 unknown token。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码和解码文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m811.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.24.0)\n",
      "Requirement already satisfied: tqdm in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: nltk in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub-0.16.4-py3.8.egg (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2022.7.1)\n",
      "Requirement already satisfied: requests in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: sympy in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: click in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=a1f60b09148c2ceac248c284aace42efbf9fb2f3464bec6cb62aa9d1430901eb\n",
      "  Stored in directory: /Users/lihongxuan/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/sgnns_xx60vdrf8dbqgsl7400000gn/T/ipykernel_20244/737711285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tokenizers\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_fx_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/logging.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.4.1\n",
      "  Downloading transformers-2.4.1-py3-none-any.whl (475 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.8/475.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (2022.7.9)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (4.64.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers==0.0.11\n",
      "  Downloading tokenizers-0.0.11.tar.gz (30 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (1.21.5)\n",
      "Requirement already satisfied: filelock in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (3.6.0)\n",
      "Requirement already satisfied: boto3 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from transformers==2.4.1) (1.24.28)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from boto3->transformers==2.4.1) (1.27.28)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from boto3->transformers==2.4.1) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from boto3->transformers==2.4.1) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==2.4.1) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==2.4.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==2.4.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers==2.4.1) (2.0.4)\n",
      "Requirement already satisfied: six in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==2.4.1) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==2.4.1) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/lihongxuan/opt/anaconda3/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers==2.4.1) (2.8.2)\n",
      "Building wheels for collected packages: tokenizers, sacremoses\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m copying tokenizers/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/tokenizers\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m running build_rust\n",
      "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m To update pip, run:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m and then retry package installation.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
      "\u001b[0m  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=ff0b9aea436be1a5ae2bbe8a5b36dec93bb3722629a75f5a578b79642839fae5\n",
      "  Stored in directory: /Users/lihongxuan/Library/Caches/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
